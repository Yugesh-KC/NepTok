{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6heXG4_FMnl1",
        "outputId": "845dfe50-064f-4bae-97d1-f4d151a16349"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\""
      ],
      "metadata": {
        "id": "uDYj7pEANsYS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path1 = kagglehub.dataset_download(\"lotusacharya/nepalinewsdataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path1)"
      ],
      "metadata": {
        "id": "C5M_GgmZm5PX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e98fef-ed4e-4963-dc78-d74a5f07758c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/lotusacharya/nepalinewsdataset?dataset_version_number=4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18.1M/18.1M [00:00<00:00, 212MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/lotusacharya/nepalinewsdataset/versions/4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path2 = kagglehub.dataset_download(\"hsebarp/oscar-corpus-nepali\")\n",
        "\n",
        "print(\"Path to dataset files:\", path2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyOhCGujJzgx",
        "outputId": "c7b000ac-2ec0-4b24-ca91-8bf7a23e5607"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/hsebarp/oscar-corpus-nepali?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 661M/661M [00:02<00:00, 271MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/hsebarp/oscar-corpus-nepali/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "target = '/content/dataset'\n",
        "os.makedirs(target, exist_ok=True)  # Ensure the target directory exists\n",
        "\n",
        "# List of source directories to iterate through\n",
        "source_dirs = [path1, path2]\n",
        "\n",
        "# Iterate over each source directory\n",
        "for source in source_dirs:\n",
        "    # Walk through the directory and subdirectories\n",
        "    for root, dirs, files in os.walk(source):\n",
        "        for file in files:\n",
        "            # Process only .txt files\n",
        "            if file.endswith('.txt'):\n",
        "                src_file_path = os.path.join(root, file)\n",
        "                dst_file_path = os.path.join(target, file)\n",
        "\n",
        "                # Handle filename conflicts by renaming if the file already exists in the target\n",
        "                if os.path.exists(dst_file_path):\n",
        "                    base, ext = os.path.splitext(file)\n",
        "                    counter = 1\n",
        "                    # Create a unique filename by appending a counter\n",
        "                    while os.path.exists(dst_file_path):\n",
        "                        dst_file_path = os.path.join(target, f\"{base}_{counter}{ext}\")\n",
        "                        counter += 1\n",
        "\n",
        "                # Copy the file from source to target\n",
        "                shutil.copy(src_file_path, dst_file_path)"
      ],
      "metadata": {
        "id": "8mVidmNNm9Vd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_file = '/content/merged.txt'\n",
        "\n",
        "with open(merged_file, 'w', encoding='utf-8') as outfile:\n",
        "    # Walk through the target directory to find all .txt files\n",
        "    for root, dirs, files in os.walk(target):\n",
        "        for file in files:\n",
        "            if file.endswith('.txt'):\n",
        "                file_path = os.path.join(root, file)\n",
        "\n",
        "                # Open and read each .txt file, then write its contents to merged.txt\n",
        "                with open(file_path, 'r', encoding='utf-8', errors='ignore') as infile:\n",
        "                    outfile.write(infile.read())  # Write the file content to merged.txt\n",
        "                    outfile.write('\\n')  # Optionally add a n"
      ],
      "metadata": {
        "id": "twzWbbixrBNn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open ('merged.txt','r') as file:\n",
        "  x=file.read()\n",
        "\n"
      ],
      "metadata": {
        "id": "wp3_AAxEcdeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df88c172-6f6b-489d-d6bb-0630f36bbe20"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "राष्ट्रपतिको घोषणापछिका जटिलतासहमतीय सरकार नबनेसम्म यही सरकार रहे मात्र रिक्तता उत्पन्न हुनेछैन अन्य\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:1000])\n",
        "del(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zcTvbBjRGdu",
        "outputId": "563ca10e-01bc-4ece-c609-d979df8cfb14"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "राष्ट्रपतिको घोषणापछिका जटिलतासहमतीय सरकार नबनेसम्म यही सरकार रहे मात्र रिक्तता उत्पन्न हुनेछैन अन्यथा संवैधानिक रिक्तता अवश्यम्भावी छ  \"\n",
            "\tमंसिर  पछि संवैधानिक शून्यता हुने हुँदा   अनुसार सरकार गठनको औपचारिक घोषणा गर्ने कदमको संकेत मंसिर  गते शीतलनिवासबाट सार्वजनिक भएपछि उत्साहित प्रतिपक्षीहरू हल्लेको झन्डाको नशामा झुम्म थिए  तर अचानक  गते राष्ट्रपतिबाट बजेट स्वीकृत हुँदा ती रन्थनिए  तत्कालै सरकारले चतुरतासाथ वैशाखमा चुनाव हुने घोषणासहित राष्ट्रपतिले भन्ने गरेको संवैधानिक शून्यतासमेत समाप्त गर्दा भने स्वयं राष्ट्रपतिलाई पनि रन्थन्याइयो  क्रिकेटमा झैं बलिङविरुद्ध ठाडो ब्याटिङ गर्ने माओवादीले यसपटक चेसको रणनीतिक चाल चले पनि राष्ट्रपतिले  गते फेरि अर्को प्रत्याक्रमण गरे संसद्को बहुमतबाट आएको माओवादी नेतृत्वको सरकार हटाउने मिसाइल सहित   \n",
            "\tतर खेल सकिएको होइन सुरु भएको हो  अब बल माओवादीको हातमा छ  संसद्बाट निर्मित वैधानिक सरकार छाडेर राष्ट्रपतिको अनुमानअनुसार कांग्रेस या अन्यको नेतृत्वमा प्रतिरक्षात्मक रणनीति अख्तियार गरी लुसुक्क खान्छन् कि प्रत्याक्रमण रणनीति लिई राष्ट्रपति र कांग्रेस या मध\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "tokenizer.train(files=\"merged.txt\", vocab_size=65536,show_progress =True)\n",
        "\n"
      ],
      "metadata": {
        "id": "WqEeOe9DnMJb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"nepali_tokenizer\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "tokenizer.save_model(save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1vhKGKknPsI",
        "outputId": "61c1def8-3469-41e0-ab0b-8126251f3fb6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nepali_tokenizer/vocab.json', 'nepali_tokenizer/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Folder path where the files are located\n",
        "folder_path = '/content/nepali_tokenizer'\n",
        "\n",
        "# List all files in the folder\n",
        "files_in_folder = os.listdir(folder_path)\n",
        "\n",
        "# Loop through each file and download it\n",
        "for file_name in files_in_folder:\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "    # Make sure it’s a file (not a directory)\n",
        "    if os.path.isfile(file_path):\n",
        "        files.download(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3j7JRryeRX30",
        "outputId": "bef28a27-9c82-434d-da32-9eadf6ae70f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_47a934af-ec87-4130-bf7e-299e846b3e9d\", \"vocab.json\", 1562511)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_38a1200d-2af7-4a4a-88d0-9118737bd1c8\", \"merges.txt\", 1113657)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=ByteLevelBPETokenizer()\n",
        "tokenizer = tokenizer.from_file(\"nepali_tokenizer/vocab.json\", \"nepali_tokenizer/merges.txt\")"
      ],
      "metadata": {
        "id": "8yJwUBJ4Vqyc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'यो एउटा नेपाली टोकनाइजर हो।'\n",
        "ids = tokenizer.encode(text).ids\n",
        "print(ids)\n",
        "for id in ids:\n",
        "  print(tokenizer.decode([id]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdj2Ag6KfMjo",
        "outputId": "f977e01a-2c67-4a51-a715-8ba6ddc50c4b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[270, 266, 545, 259, 287, 265, 277, 259, 267, 272, 380, 266, 647, 259, 2963, 295, 478]\n",
            "य\n",
            "ो\n",
            " एउट\n",
            "ा\n",
            " न\n",
            "े\n",
            "प\n",
            "ा\n",
            "ल\n",
            "ी\n",
            " ट\n",
            "ो\n",
            "कन\n",
            "ा\n",
            "इजर\n",
            " ह\n",
            "ो।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c3fFsalyhtE9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}